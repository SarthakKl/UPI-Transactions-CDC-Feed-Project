{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85e9d363-a46e-4c8e-812a-40c73bc7f9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# source_table = 'cdc_feed_project_catalog.default.raw_upi_txns'\n",
    "\n",
    "# cdc_stream = spark.readStream.format('delta').option('readChangeFeed', 'true').table(source_table)\n",
    "\n",
    "# query = cdc_stream.select(\n",
    "#     \"transaction_id\",\n",
    "#     \"upi_id\",\n",
    "#     \"merchant_id\",\n",
    "#     \"transaction_amount\",\n",
    "#     \"transaction_timestamp\",\n",
    "#     \"transaction_status\",\n",
    "#     \"_change_type\",  # CDC change type\n",
    "#     \"_commit_version\",\n",
    "#     \"_commit_timestamp\"\n",
    "# ).writeStream.format('console').outputMode('append').start()\n",
    "\n",
    "# query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0550d7-876a-438d-b8b6-d0f55b6dbf23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "aggregated_table = 'cdc_feed_project_catalog.default.merchant_table'\n",
    "source_table = 'cdc_feed_project_catalog.default.raw_upi_txns_v1'\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "         create table if not exists cdc_feed_project_catalog.default.merchant_table (\n",
    "             merchant_id string,\n",
    "             total_sales decimal(10,2),\n",
    "             total_refunds decimal(10,2),\n",
    "             net_sales decimal(10,2)\n",
    "         ) \n",
    "         using delta\n",
    "          \"\"\")\n",
    "\n",
    "def batch_processing(batch_df, batch_id):\n",
    "    aggregated_df =  batch_df \\\n",
    "        .filter(col('_change_type').isin('insert', 'update_postimage')) \\\n",
    "        .groupBy('merchant_id') \\\n",
    "        .agg(\n",
    "            sum(when(col('transaction_status') == 'completed', col('transaction_amount')).otherwise(0)).alias('total_sales'),\n",
    "            sum(when(col('transaction_status') == 'refunded', -col('transaction_amount')).otherwise(0)).alias('total_refunds')\n",
    "        ).withColumn('net_sales', col('total_sales') + col('total_refunds'))\n",
    "\n",
    "    deltaTable = DeltaTable.forName(spark, aggregated_table)\n",
    "\n",
    "    deltaTable.alias('target').merge(\n",
    "        aggregated_df.alias('source'),\n",
    "        'target.merchant_id = source.merchant_id'\n",
    "    ).whenMatchedUpdate(\n",
    "        set = {\n",
    "            'total_sales': \"source.total_sales + target.total_sales\",\n",
    "            'total_refunds': \"source.total_refunds + target.total_refunds\",\n",
    "            'net_sales': \"source.net_sales + target.net_sales\"\n",
    "        }\n",
    "    ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "cdc_stream = spark.readStream.format('delta').option('readChangeFeed', 'true').table(source_table)\n",
    "print('Read Stream Started.................')\n",
    "\n",
    "cdc_stream.writeStream.foreachBatch(batch_processing).outputMode('update').start().awaitTermination()\n",
    "print('Write Stream Started................')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cdc_merchant_aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
